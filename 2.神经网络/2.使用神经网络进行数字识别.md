# 使用神经网络进行数字识别

## 1.加载数据集

### 1.1 加载数据集

1.将数据加载到变量 $X$ 和 变量 $y$ 中：

- 数据集包含5000个手写数字的训练样本

- 每个训练样本都是数字的 `20像素x20像素`的灰度图像

  - 每个像素都由一个浮点数表示，表示该位置的灰度强度

  - `20x20`像素网格被 ”展开“成一个 `400`维矢量（即将图像展平）

  - 每个训练样本都是数据矩阵 $X$ 中的一行 $x$

  - 这为我们提供了一个 `5000x400`的矩阵， $X$ 中的每一行都是一个训练样本

    - $$
      \mathbf{X} = 
      \begin{pmatrix}
      ---(x^{(1)})--- \\
      ---(x^{(2)})--- \\
      \vdots
      ---(x^{(m)})--- \\
      \end{pmatrix}
      $$

- 训练集的第二部分是一个 `5000x1`的一维向量 $\mathbf{y}$ ，其中包含训练集的标签

  - $y=0$ ：表明图像中的数字为 $0$
  - $y=1$ ：表明图像中的数字为 $1$
  - 依此类推

```python
# load_data()是一个自定义用于加载数据集的方法
X, y = load_data()
```



### 1.2 查看数据集

1.熟悉数据集的一个简单的方法是**打印出每一个变量并查看它包含的内容**：

- 打印变量 $\mathbf{X}$ 和 $\mathbf{y}$ 中的第一个元素：

```python
print('The first element of X is:', X[0])
print('The first element of y is:', y[0,0])
print('The last element of y is:', y[-1,0])
```

2.熟悉数据集的另一种方法是**查看其维度**：

```python
print(f'The shape of X is: {X.shape}')
print(f'The shape of y is: {y.shape}')
```

3.熟悉数据集的第三种方法是**可视化数据集**：

- 在该数字识别的例子中，我们可以随机选择64行，将每行映射回 `20x20`的灰度图像，并将这些图像一起显示

- 并且将每个图像的标签显示在图像的上方

- ```python
  import warnings
  warnings.simplefilter(action='ignore', category=FutureWarning)
  # You do not need to modify anything in this cell
  
  m, n = X.shape
  
  fig, axes = plt.subplots(8,8, figsize=(5,5))
  fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.91]) #[left, bottom, right, top]
  
  #fig.tight_layout(pad=0.5)
  widgvis(fig)
  for i,ax in enumerate(axes.flat):
      # Select random indices
      random_index = np.random.randint(m)
      
      # Select rows corresponding to the random indices and
      # reshape the image
      X_random_reshaped = X[random_index].reshape((20,20)).T
      
      # Display the image
      ax.imshow(X_random_reshaped, cmap='gray')
      
      # Display the label above the image
      ax.set_title(y[random_index,0])
      ax.set_axis_off()
      fig.suptitle("Label, image", fontsize=14)
  ```

  

## 2.建立模型

### 2.2 模型表示

1.在本例中，我们可以建立如下的神经网络：

- 它包含 2个具有 `ReLu` 激活的密集层（全连接层），然后是具有线性激活的输出层
  - 回想一下，我们的输入是数字图像的像素值
  - 由于图象是 `20x20`的，所以输入的特征数是 `400`
- ![image-20240106112338365](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106112338365.png)
  - 第一层具有25个神经元，第二层具有15个神经元，第三层具有10个神经元
- 如果神经网络中的一层有 $s_{in}$ 个单元，下一层有 $s_{out}$ 个单元，则这一层的参数为：
  - $\mathbf{W}$ 将是维度为 $s_{in} * s_{out}$  的矩阵
  - $\mathbf{b}$  将是一个包含 $s_{out}$ 个元素的向量



### 2.3 模型实现

#### 2.3.1 每一层单元数

1.`Tensorflow`模型是逐层构建的，我们可以指定每一层的单元数（也即指定了每一层的输出尺寸），这将确定下一个层的输入尺寸，其中第一层的输入维度可以由`mode.fit` 语句自动从输入数据中识别得到；

**注意**：我们也可以添加一个输入层，用于指定第一层的输入维度：

```python
tf.keras.Input(shape=(400,)),			# specify input shape
```



#### 2.3.2 `Softmax`函数的放置位置

1.如果在训练期间将`softmax` 函数与损失函数结合在一起，而不是直接在输出层使用`softmax`激活函数，可以提高数值稳定性，但这在构建模型和使用模型时都会产生一定影响：

- 构建模型时：

  - 最后的密集层（全连接层）应该使用 `线性激活函数`（实际上是没有使用激活函数）

  - 编译模型在指定损失函数时，需要使用`from_logits=True`选项：

    - ```python
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
      ```

  - 注意：这不会影响目标的形式，在损失函数为`SparseCategorialCrossentropy`的情况下，目标是预期的数字`0-9`

- 使用模型时：

  - 在使用这种方式时，模型输出的不是概率，如果要输出概率，则需要额外对模型的输出使用`softmax`函数



#### 2.3.3 建立模型

```python
# UNQ_C2
# GRADED CELL:Sequential model
tf.random.set_seed(1234)	# for consistent results
model = Sequential(
	[
        tf.keras.Input(shape=(400,)),
        Dense(25, activation='relu', name="L1"),
        Dense(15, activation='relu', name="L2"),
        Dense(10, activation='linear', name="L3")
    ], name="my_model"
)

model.compile(
	loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
)
```



## 3.训练模型

### 3.1 训练模型

1.使用`model.fit`语句来进行训练模型：

```python
history = model.fit(
	X,y,
    epochs=100
)
```

在训练过程中，会有如下打印输出：

![image-20240106115151467](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106115151467.png)

- `Epoch 1/100` 描述模型当前正在运行的轮次
- 为了提高训练效率，训练数据集被分为 **”批次“**，`Tensorflow`中批处理的默认大小为`32`，我们的数据集有5000个样本，则大约有`157`个批次



### 3.2 监控损失

1.通过监控成本（损失）可以跟踪梯度下降的进度：

- 理想情况下，成本会随着算法迭代次数的增加而降低
- `model.fit`会返回各种指标，包括损失，这在上面的`history`变量中得到了体现，这可以用于监控损失：

![image-20240106115641441](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106115641441.png)



## 4. 使用模型

1.要使用模型进行预测，使用`predict`方法：

```python
# 取得样本，该样本是一个包含数字2的图像
image_of_two = X[1015]

prediction = model.predict(image_of_two.reshape(1,400))		# prediction

print(f"predicting a Two: \n{prediction}")
print(f"Largest Prediction index: {np.argmax(prediction)}")
```

2.如果要输出概率，则需要对输出应用`softmax`函数：

```python
prediction_p = tf.nn.softmax(prediction)

print(f" predicting a Two. Probability vector: \n{prediction_p}")
print(f"Total of predictions: {np.sum(prediction_p):0.3f}")
```

3.如果要返回表示预测目标的整数，则需要返回最大概率的索引，可以使用`Numpy`的`argmax`函数完成：

```python
y_hat = np.argmax(prediction_p)
print(f"np.argmax(prediction_p): {y_hat}")
```

