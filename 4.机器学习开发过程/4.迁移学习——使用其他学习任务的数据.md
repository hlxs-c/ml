# 迁移学习——使用其他学习任务的数据

>  对于没有那么多数据的应用程序，**迁移学习** 是一种很好的技术，它可以让我们使用来自不同任务的数据来帮助我们的应用程序。



## 1.引入`迁移学习`

![image-20240107161148372](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240107161148372.png)

假设我们想要识别从0到9的手写数字，但是我们没有那么多这些手写数字数字的标记数据，则可以利用**迁移学习**的方法：

1. 假设我们找到了一个非常大的数据集，其中包含了一百万张猫、狗、汽车、人等的图片，共一千个类别，然后，我们可以开始在这个包含一千个不同类别的一百万张图像的大型数据集上训练神经网络，并训练算法将图像 X 作为输入，学习识别这1000个不同类别中的任何一个；
   - 在这个过程中，可以得到最终学习的参数 $ (\mathbf{W}^{(1)},\mathbf{b}^{(1)})、(\mathbf{W}^{(2)},\mathbf{b}^{(2)})、(\mathbf{W}^{(3)},\mathbf{b}^{(3)})、(\mathbf{W}^{(4)},\mathbf{b}^{(4)})、(\mathbf{W}^{(5)},\mathbf{b}^{(5)})$
2. 应用**迁移学习**，**复制此神经网络**，并**利用步骤一中最终学习得到的参数对神经网络的各层参数进行赋值初始化**，但对于最后一层，则需要使用一个更小的输出层进行替换（只有10个而不是1000个输出单元），并且由于最后一层（输出层）的维度已经更改，因此需要提出新的参数$(\mathbf{W}^{(5)},\mathbf{b}^{(5)})$，并需要从头开始训练，而不是仅仅从之前的神经网络中复制它。



在迁移学习中，我们可以做的是使用（复制）前4层的参数，实际上是除最终输出层之外所有层作为新神经网络参数的起点（初始化），然后运行优化算法，例如梯度下降或`Adam`优化算法。具体来说，关于如何训练新神经网络参数，有两种选择：

1. **只训练输出层参数**：可以将从旧任务中学习得到的参数（前4层的参数）固定作为新神经网络中的前4层参数，然后使用随机梯度下降或`Adam`等算法进行优化，仅训练更新输出层参数 $(\mathbf{W}^{(5)},\mathbf{b}^{(5)})$；
2. **训练网络中的所有参数**：仅仅使用旧神经网络中前4层网络参数对新神经网络前4层参数进行**初始化**，而不固定前4层复制而来的参数，然后使用随机梯度下降或`Adam`算法等进行优化，优化更新所有层（从第一层到输出层）的所有参数；

如果新任务的数据集非常小，那么使用方法1可能会好一些，但如果有一个稍微大一点的训练集，则方法2可能会好一些。



这种方法称为**迁移学习**，因为直觉是通过学习识别猫、狗、牛、人等，希望它已经为处理图像输入的早期层学习了一些合理的参数集，然后通过将这些参数转移到新的神经网络，新的神经网络从一个更好的地方开始训练优化，这样就可以进一步学习新任务数据集中的特征并最终得到一个较好的模型。



这两个步骤：

1. 首先在大型数据集上进行训练
   - 这一步被称为**监督预训练**
2. 然后在较小的数据集上进一步调整参数
   - 这一步被称为**微调**，这可以在其中获取已初始化或从**监督预训练**中获得的参数，然后进一步运行梯度下降以**微调** 权重以适应新任务中的特定应用 

如果我们仅仅有一个很小的数据集，那么我们能够从这些不太相关的任务的数百万张图像中学习实际上可以极大地帮助我们学习算法的性能。



**迁移学习的一个好处是**：我们可能并不需要成为进行**监督预训练**的人。

- 对于很多神经网络，已经有研究人员在大数据集上训练了神经网络，并在互联网上发布了经过训练的神经网络，免费授权给任何人下载和使用。
- 则我们只需要下载其他人花费数周训练的神经网络，然后将输出层替换为自己的输出层并执行**两种训练新神经网络参数**的方法中的其中之一即可，然后就可以调整一个别人已经进行过**监督预训练**的神经网络，我们只需要做一些微调就可以快速获得一个在我们的任务上表现良好的神经网络

> 下载别人已经训练过并免费提供的预训练模型是其中的一种技术，通过在机器学习社区中相互构建，我们都可以获得更好的结果。



## 2.为什么迁移学习有效

![image-20240107164324233](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240107164324233.png)

以上述为例，为什么可以利用通过识别猫、狗、汽车和人获得的参数来帮助识别像手写数字这样不同的东西？

这是一种直觉，如果我们正在训练神经网络来检测图像中的不同对象，

- 那么神经网络的第一层可能会学习检测图像中的边缘（这些是图像中用于检测边缘的低级特征）；
- 神经网络的下一层将学习将边缘组合在一起以检测转角点；
- 再下一层可能已经学会检测一些更复杂的东西，它们存储通用形状（如基本曲线）；

这就是为什么通过学习检测大量不同的图像，我们正在教神经网络学习检测边缘、角落和基本形状。

同样的，这就是为什么通过训练神经网络来检测猫、狗、汽车和人等各种事物，我们**正在帮助神经网络学习检测图像的这些非常通用的特征并找到边缘、角落、曲线和基本形状**。这对于许多其他计算机视觉任务是很有用的，例如识别手写数字。

**注意**：**预训练的一个限制是在预训练和微调步骤中使用的图像类型x必须相同**。

- 例如，如果要解决的最终任务是计算机视觉任务，那么预训练步骤必须是在和最终任务相同类型的输入上训练的神经网络，即输入的图像的尺寸必须是相同的。
- 如果目标是构建一个语音识别系统来处理音频，那么在图像上预训练的神经网络对音频就不会有太大帮助。相反的，则需要一个在音频数据上进行预训练的神经网络，然后再在自己的音频数据集上进行微调（其他类型的应用程序也是如此）。



## 3.迁移学习的总结

1. 下载神经网络，其参数已在与我们的应用程序具有相同输入类型的大型数据集上进行了**预训练**；

   - 该输入类型可以是图像、音频、文本或其他类型；
   - 或者如果不想下载神经网络也可以自己进行预训练，但在实践中，如果使用图像，更常见的是下载别人的预训练神经网络，然后根据自己的数据进一步训练或微调网络；

2. 然后根据自己的数据进一步训练或微调网络

   