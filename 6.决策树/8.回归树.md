# 回归树

> 本文将描述如何将决策树应用于回归算法，以便可以预测一个数字。



假设现在有一个 **回归问题**——预测动物的重量，如下图所示：

![image-20240112144347374](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240112144347374.png)

数据集和猫分类的数据集类似，但是注意，在该数据集中：

- `耳朵的形状、脸的形状、是否有胡须` 是三个特征
- 而`动物的重量` 是 **标签（目标值）**，是我们想要预测的值



## 1.如何使用已经构建好的决策树进行回归问题的预测

假设我们已经为上述的回归问题构建了一棵决策树，如下图所示：

![image-20240112144803800](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240112144803800.png)

现在的问题是，在已经构建出上述的一棵树之后，如何使用该树进行该回归问题的预测？

例如，如果有一个测试样本归结到左边的第一个叶子节点时，我们应该预测这个动物的重量是多少？

**答案是**：决策树将根据这个叶子节点中所有训练样本的重量（目标值）的平均值进行预测

例如，在左边的第一个叶子节点中，有4个训练样本，且其重量（目标值）分别为 `7.2、8.4、7.6、10.2`，其平均值为 $8.35$， 则在该叶子节点上，我们将预测归结到该叶子节点的测试样本的目标值为 $8.35$，依次类推，得到如下图所示：

![image-20240112145542014](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240112145542014.png)

因此，这个模型将做的是：如果给定一个新的测试样本作为输入，将跟随决策节点直到它到达一个叶子节点，然后以 “我们刚刚通过取在训练期间下降到该叶子节点的所有训练样本的重量（目标值）的平均值 ” 作为该叶子节点的预测值。





## 2.如何构建用于回归问题的决策树

构建**用于回归问题的决策树** 和 **用于分类问题的决策树** 相似，都需要做出 **关键决定**——**如何选择使用哪一个特征进行拆分？**

下面以上述的例子来进行说明在构建用于回归问题的决策树时，如何选择使用哪一个特征进行拆分：

1. 首先，和构建用于分类问题的决策树类似，我们将 **遍历所有可能的特征**，并分别使用选择的特征进行拆分：

   - ![image-20240112150853623](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240112150853623.png)
   - 在得到上述结果后，问题变为：鉴于使用这三个可能的特征进行拆分的结果，如何选择一个最合适的拆分特征？
   - **答案**：**在构建回归树时，我们不是试图减少熵（这是我们对分类问题的杂质的度量），而是尝试减少每个数据子集的值 $y$ （目标值）的方差**。

2. 计算拆分之后左节点中训练样本子集的方差和右节点中训练样本子集的方差：

   - 方差的计算：先计算期望（平均值）$E$，则 $方差= \sum_{i=1}^m (y_i - E)^2$

3. 将左右分支的训练样本子集的 **方差** 组合为一个数字以对使用该特征进行拆分的结果进行质量评估：

   - 和构建 **用于分类问题的决策树** 类似，为了判断使用某个特征进行拆分的质量评估，需要将拆分结果中的左右分支的 **结果数值** 组合为一个数值以进行评估——**使用加权平均值**；

   - 在这里，需要使用到相同的定义：

     - $$
       w^{left} = \frac{左分支的训练样本的数量} {根节点的训练样本的总数} \\
       w^{right} = \frac{右分支的训练样本的数量} {根节点的训练样本的总数} \\
       $$

   - 则
     $$
     拆分结果的方差的的加权平均值=w^{left}*左分支的方差 + w^{right}*右分支的方差
     $$

   - 得到如下图的结果：

   - ![image-20240112152126679](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240112152126679.png)

4. 选择一个最佳的特征以用于拆分：

   - 在计算了使用每个特征进行拆分得到的结果的 **方差的加权平均值** 之后，选择最佳的拆分特征的一个方法是 **选择最低的加权方差值**；

   - 但是和计算信息增益类似，我们可以对这个式子进行再做一个修改——就像分类问题一样，我们不只是计算平均加权熵，而是计算了熵的减少量（信息增益）。则对于回归问题，我们也可以类似地计算**方差的减少量**。

   - $$
     方差的减少量 = 根节点的方差 - 左右分支的方差的加权平均值
     $$

   - ![image-20240112152727098](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240112152727098.png)

   - 就像之前为决策树选择能够提供最大信息增益的特征进行拆分一样，我们应该**选择能够为我们提供最大方差减少量的特征**；



在明白了如何做出在构建回归树时的关键决定——如何选择最佳的用于拆分的特征？

其余的构建步骤与构建用于分类问题的决策树的类似。