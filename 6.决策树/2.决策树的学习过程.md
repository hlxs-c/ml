# 决策树的学习过程

> 本文描述**构建决策树需要做的事情的全过程**。

给定一个包含10个猫狗样本的训练集，如下图所示：

![image-20240111145008332](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240111145008332.png)

**构建决策树需要做的事情的全过程**：

1. 决定在根节点上使用什么特征
2. 关注决策树的左侧部分（左分支），以决定将哪些节点放在那里
   - 特别是，要拆分的特征是什么，或者我们接下来要使用什么特征
   - 当不能继续分裂时，不需要再使用某个特征进行拆分，而是创建一个叶节点（预测节点）
3. 关注决策树的右侧部分（右分支），重复左侧部分的工作（决定将哪些节点放在那里）



在上述这个过程中，我们必须在算法的各个步骤中做出几个关键决定：

1. 如何选择在每个节点上使用哪些特征进行拆分
   - **决策树将选择尝试将节点最大化纯度的特征进行拆分**
   - 最大化节点的纯度指的是一个节点只有尽可能少的类别混合在一起
   - <img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240111155306757.png" alt="image-20240111155306757" style="zoom:50%;" />
2. 决定合适停止分裂
   - 当一个节点中的所有样本都是同一个类别时
   - 当分裂一个节点将会导致超越**最大深度**时停止分裂
     - 其中**最大深度** 是一个 **参数**
     - 在决策树中，节点的深度定义为从表示最顶部的节点到该特定节点所需要的跳数，例如根节点的深度为0（因为从根节点到根节点所需要的跳数为0）
     - 可能想要**限制决策树的深度**的一个原因是确保我们的树不会变得太大和笨重，其次，**通过保持一个较小的决策树，它不会太容易出现过度拟合**
   - 当分裂一个节点对 **节点纯度** 的提升小于一个阈值时
   - 当一个节点中的样本数量低于某个阈值时

