# 评估一个假设

1.当我们确定学习算法的参数的时候，我们考虑的是选择参数来使**训练误差最小化**，但是需要注意的是，仅仅是因为这个假设有一个很小的训练误差，并不能说明它就一定是一个好的假设函数，例如，过拟合的假设函数有一个很小的训练误差，但将其推广到新的训练集上时就不再使用了。

2.对于简单的例子，可以通过对假设函数 $h(x)$ 进行画图，然后观察图形趋势来判断假设函数是否过拟合或欠拟合，但是对于含有多个特征变量的假设函数，是无法通过画图来观察假设函数的正确性的。

3.为了评估假设函数是否正确拟合数据，我们**可以将数据划分为 `训练集` 和 `测试集`**：

- 通常用 70%的数据作为训练集，用剩下的 30% 的数据作为测试集；
- **注意**：训练集和测试集均需要含有各种类型的数据，通常我们需要对数据进行打乱，然后再划分为训练集和测试集；

![image-20240106150028954](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106150028954.png)



4.**典型的训练和测试学习算法的方法步骤**：

1. 首先，需要使用训练集进行训练学习得到模型参数；
   1. 具体来说，就是需要最小化训练误差，也即代价函数 $J$ 的值；
2. 计算测试误差



5.**计算测试误差的方法**：

1. 线性回归问题：利用测试集数据计算代价函数 $J$ 的值
2. 分类问题（逻辑回归）：
   1. 方法1：利用测试集数据计算代价函数 $J$ 的值
   2. 方法2：错误分类（0/1 错误分类）：
      - 定义：

$$
err(f_{w,b}(x),y) = 
\begin{cases}
1 & if \space \space f_{w,b}(x) \ge 0.5, y=0 & or & if \space \space f_{w,b}(x) \lt 0.5, y=1 \space \\ \\ 
0 & otherwise
\end{cases}
\\\\
1.当实际标签为0预测为1 或者 实际标签为1预测为0 （即预测错误）时，err(f_{w,b}(x),y) = 1 \\
2.其他情况（即预测正确）时，err(f_{w,b}(x),y) = 0
$$

 此时可以利用 $err(f_{w,b}(x),y)$ 来定义测试误差：
$$
Test \space error = \frac{1}{m_{test}} \sum_{i=1}^{m_{test}} err(f_{w,b}(x_{test}^{(i)}),y^{(i)}) \\\\
即定义测试误差为预测错误分类的比率
$$