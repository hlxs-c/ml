# 决定下一步做什么

## 1.6种方法

1.获得更多的训练样本——解决过拟合（高方差）

2.尝试减少特征的数量——解决过拟合（高方差）

3.尝试获得更多的特征——解决欠拟合（高偏差）

4.尝试增加多项式特征——解决欠拟合（高偏差）

5.尝试减少正则化系数 $\lambda$ ——解决欠拟合（高偏差）

6.尝试增加正则化系数 $\lambda$ ——解决过拟合（高方差）



## 2.神经网络的方差和偏差

![img](http://www.ai-start.com/ml2014/images/c5cd6fa2eb9aea9c581b2d78f2f4ea57.png)

使用较小的神经网络，类似于参数较小的情况，容易导致欠拟合（高偏差），但计算代价较小使用较大神经网络，类似于参数较多的情况，容易导致过拟合（高方差），虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。

通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。

对于神经网络中的隐藏层的层数的选择：通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据集划分为`训练集` 、`交叉验证集`、`测试集`，针对不同隐藏层层数的神经网络训练，然后选择交叉验证集代价最小的神经网络。



