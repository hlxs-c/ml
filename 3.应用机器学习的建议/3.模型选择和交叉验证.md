# 模型选择和交叉验证

## 1.问题引入

假设我们要在10个不同次数的二项式模型之间进行选择：

![img](http://www.ai-start.com/ml2014/images/1b908480ad78ee54ba7129945015f87f.jpg)

显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表能够推广至一般情况，我们应该选择一个更能够适应一般情况的模型，那应该如何选择一个合适的模型呢？



## 2.将数据划分为`训练集`、`验证集`和`测试集`

### 2.1 描述

在 [模型评估](C:\Data\Markdown\MachineLearning\3.应用机器学习的建议\2.评估一个假设.md) 中，我们将数据划分为训练集和测试集，训练集用于训练模型，而测试集用来评估模型，但为了更好的选择合适的模型，除了将数据划分为训练集和测试集，一般还要划分出一个验证集，使用交叉验证集来帮助选择模型，即将数据划分为：

- 60%：训练集
- 20%：验证集（交叉验证集）
- 20%：测试集



### 2.2 为什么需要划分为`训练集`、`验证集`和`测试集`

如果我们仅仅将数据集划分为`训练集`和`测试集`，则在训练过程中，由于我们会多次使用`测试集`来评估模型并进行调整模型的超参数然后重新训练，可能会引入一种称为 **”数据泄露“** 的问题。

具体来说，在进行`模型选择`、`超参数调整`或`特征选择`等过程中，我们可能会使用测试集来指导决策，例如选择具有最佳性能的模型或参数，但这样做的问题在于，我们**在某种程度上将`测试集`的信息引入了我们的决策过程中**。

而由于我们使用了`测试集`的信息，模型在测试集上的性能可能会过于乐观，这是因为模型在训练过程中已经间接了解到了测试集的特征和模式。当我们将该模型部署到真实世界的未知数据上时，它的性能可能不如在测试集上所显示的那样好。

所以，如果我们仅仅使用`测试集` 来评估模型的性能，由于模型可能已经在训练集上进行了多次调整和优化（每次调整和优化，例如调整超参数重新训练，则会先在测试集上进行性能评估），因此由于 **”数据泄露”** 的问题，模型可能会记住一些与`测试集` 相关的特征和模式。因此，`测试集`将不能提供对模型在未见过的数据上的泛化能力的准确评估。

为了更好地评估模型的泛化能力，就需要引入`验证集`。在训练过程中，我们可以使用`验证集`来监控模型的性能，通过在`验证集`上评估模型，我们可以了解模型是否在过拟合了训练数据，以及是否可以泛化到未见过的数据，而不需要使用`测试集` 来评估模型的性能，从而在`模型选择`和`超参数调整`时，可以利用`验证集`而不是`测试集`来评估模型的性能，然后再根据评估结果来进行选择和调优，使得能够获得更好的泛化能力。

最终，`测试集`可以被保留用于最终评估模型的性能（`测试集`对于最终调优好的模型来说就是完全未知的数据）。通过在`测试集`上进行评估，我们可以得到模型在真实世界中的表现，因为测试集包含模型未曾见过的数据。

因此，将数据划分为训练集、验证集和测试集可以更准确地评估模型的泛化能力，并帮助我们做出更可靠的决策。





## 3.模型选择的方法

1. 使用**`训练集`**训练出10个模型
2. 用10个模型分别对**`交叉验证集`**计算得到**`交叉验证误差`**（代价函数的值）
3. 选取`交叉验证代价函数值`最小的模型
4. 用步骤3选出的模型对**`测试集`**计算得到推广误差（代价函数的值）（即对最终选择的模型进行一个评估）

![image-20240106180937737](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106180937737.png)



**注意**：通常这些误差中都不包含训练目标中包含的`正则化项`

**注意**：`Training error` 、`Cross validation error`和`Test error`与 训练过程中的代价函数 $J(\mathbf{w},b)$ 并不完全等价，训练过程中的代价函数 $J(\mathbf{w},b)$ 可能会包含 `正则化项`，训练过程中的代价函数 $J(\mathbf{w},b)$ 是我们要优化的目标，而 `Training error`、`Cross validation error`等是用于在模型选择、超参数调优时的一个评估量，用于判断模型或参数是否合适。



![image-20240106181813497](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106181813497.png)



在必须对模型做出决策，例如拟合参数或者选择模型架构时，例如神经网络架构或多项式的次数，如果正在拟合线性回归，那么就**让所有这些决策都仅使用训练集和交叉验证集做出决策，并且在就学习算法做出决策时不使用测试集**。

**只有在我们想出一个模型作为我们的最终模型之后，才可以在测试集上对其进行评估，并且因为我们没有使用测试集做出任何决策，这可以确保我们的测试集是公平的（包含未知数据），则可以保证测试集可以对我们的模型对型数据的泛化能力进行一个良好的估计**。