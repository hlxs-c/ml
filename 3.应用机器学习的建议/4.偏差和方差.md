# 通过偏差和方差来进行诊断

## 1.问题引入

在运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：

- 偏差比较大——欠拟合问题
- 方差比较大——过拟合问题

![image-20240106183232820](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106183232820.png)

**因为上述图中的仅是单个特征的问题，所以我们可以绘制函数 $f_{\mathbf{w},b}$ 并像上图一样查看它，但是如果我们的问题有更多的特征，那么我们就无法绘制模型 $f_{\mathbf{w},b}$ 并可视化它是否较好地拟合了数据。**



## 2.方法描述

1.当问题有多个特征时，我们无法绘制模型 $f_{\mathbf{w},b}$ 并可视化它是否较好地拟合了数据，则此时**一种更系统的诊断方法或找出算法是否具有`高偏差或高方差` 的方法是查看我们的算法在`训练集` 和 `交叉验证集` 上的性能**。

2.以上图为例：

![image-20240106184209219](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106184209219.png)

- **欠拟合（高偏差）**：
  - 在欠拟合的情况下，因为模型预测和样本目标之间存在很大的误差，所以 $J_{train}$ 很很高；而对于模型从未见过的数据，其预测和真实标签之间也会存在很大的误差，所以 $J_{cv}$ 也会很高；
  - 欠拟合（高偏差）的算法的一个特征是它在`训练集`上的表现很差，即 $J_{train}$ 很高
  - 所以 当$J_{train}$ 很高时，就说明该算法具有高偏差（欠拟合）
- **过拟合（高方差）**：
  - 在过拟合的情况下，因为模型在训练集上做的很好，非常拟合训练集数据，所以 $J_{train}$ 很低；但是，如果对于模型从未见过的数据，其效果会很差，所以 $J_{cv}$ 很高
  - 过拟合（高方差）的算法的一个特征是它在`训练集`上的表现很好，而`验证集`表现很差，所以$J_{cv}$ 会远远高于 $J_{train}$；
  - 所以 当 $J_{cv} \gt \gt J_{train}$ 时，就说明该算法具有高方差（过拟合）
- 综上，我们所做的重点是**计算 $J_{train}$ 和 $J_{cv}$ 并查看 $J_{train}$ 是否过高 或者 $J_{cv}$是否远远高于$J_{train}$**；
  - 通过此方法，即使我们不能绘制函数 $f_{\mathbf{w},b}$，这也能让我们了解算法是否具有高偏差或高方差；



## 3.理解偏差和方差

 将 `训练集` 和 `交叉验证集` 的代价函数值（误差）与多项式的次数（模型的最高维度）绘制在同一张图表上来帮助分析：

![image-20240106162903436](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106162903436.png)

![image-20240106163009611](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106163009611.png)

- 对于训练集，当模型的维度 $d$ 较小时，模型拟合程度更低，误差较大；随着 $d$ 的增长，拟合程度提高，误差减小；

- 对于交叉验证集，当模型的维度 $d$ 较小时，模型拟合程度低，误差较大；随着 $d$ 的增长，误差呈现先减小后增大的趋势，转折点（最低点）时模型开始过拟合训练数据集的时候；
- 当交叉验证集的误差较大时，根据上面的图，我们可以判断是方差较大还是偏差较大：
  1. 偏差较大（欠拟合）： $J_{train}(\theta)$ 很大，且 $J_{train}(\theta) \approx J_{cv}(\theta)  $
  2. 方差较大（过拟合）：$J_{train}(\theta)$ 很小，且 $ J_{cv}(\theta) \gt\gt J_{train}(\theta)$



## 4.诊断偏差和方差

![image-20240106185948013](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240106185948013.png)



> 高偏差和高方差同时出现的情况：模型可能过拟合了部分训练集中的样本数据，同时欠拟合了训练集中的部分样本数据，导致在训练集和验证集中的表现都交叉。
