# 倾斜数据集的误差指标

## 1.问题引入

如果我们正在开发一个机器学习应用程序，其中`正例` 与 `负例` 的比例非常偏斜，与 `50-50`相差很大，那么通常的**误差指标**（如准确度）的效果不佳。



假设我们正在训练一个二元分类器，以根据实验室测试或患者的其他数据检测患者的罕见疾病：

- 如果存在疾病，则 $y=1$；
- 如果不存在疾病，则 $y=0$；

 假设我们发现在测试集上达到了 $1 \%$ 的错误，那么诊断正确率为 $99 \%$，这似乎是一个很好的结果，但事实证明，如果这是一种罕见疾病，则$y=1$非常罕见。

甚至，如果只有 $0.5 \%$ 的病人患这个病，则如果我们直接让模型永远输出 $y=0$ ，即模型代码如下：

```python
print("y=0")
```

则因为只有 $0.5 \%$ 的病人患有该病，则这个不需要学习的算法的准确率也能达到 $99.5\%$ 的准确率，这个不需要训练的愚蠢的模型的准确率甚至高于经过训练之后的模型。



通过上述的例子来看，在处理 **偏斜数据集**的问题时，仅仅使用**分类误差** 或 **准确率** 来确定学习算法的性能是不够合适的，还应该使用不同的**误差度量**：

- 特别的，一对常见的错误指标是**精确率** 和 **召回率**



## 2.精确率和召回率

在某些**偏斜数据集**的问题中， $y=1$ 可能将是罕见的类别，例如上述问题中想要预测的罕见疾病。特别的，要用一种罕见的有用类别来评估学习算法的性能，**可以构建所谓的混淆矩阵**，它是一个 `2x2` 的矩阵或者是 `2x2`的表，如下所示：

![image-20240110155944305](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240110155944305.png)

将分类划分为这4个单元之后，接下来就可以计算两个常见的指标——**精度（精确率）和召回率**

![image-20240110160414230](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240110160414230.png)

- **精度（精确率）**：

  - $$
    Precision = \frac{True \space Positives}{predicted \space positive}
    = \frac{True \space Positives}{True \space Pos + False \space Pos }
    $$

  - **精确率** 是针对 **预测结果** 而言的，它表示的是**预测为正的样本中有多少是真正的正样本**

  - 预测为正有两种可能：一种是把正类预测为正类（TP），另一种是把负类预测为正类（FP），则：

    - $$
      P = \frac {TP}{TP + FP}
      $$

      

- **召回率**：

  - $$
    Recall = \frac{True \space Positives}{actual \space positive}
    = \frac{True \space Positives}{True \space Pos + False \space Neg }
    $$

  - **召回率** 是针对原来的**样本** 而言的，它表示的是**样本中的正例有多少被正确预测了**

  - 也有两种可能：一种是把原来的正类预测为正类（TP），另一种就是把原来的正类预测为父类（FN），则

    - $$
      R=\frac{TP}{TP+FN}
      $$

      

**准确率（Accuracy）**：模型判断正确的数据（TP+TN）占总数据的比例
$$
Acc = \frac{TP+TN}{TP+TN+FP+FN}
$$

- **准确率**的缺点：准确率是分类问题中最简单也是最直观的评价指标，但存在明显的缺陷。比如，当负样本占 $99\%$ 时，分类器把所有样本都预测为负样本也可以获得 $99\%$ 的准确率。所以，当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。



## 3.精确率和召回率之间的平衡

在上述预测患者是否患有罕见疾病的例子中：

- **高精度**意味着如果换这个被诊断含有这种罕见疾病，那么该患者可能确实患有这种疾病，并且这是一个较为准确的诊断
- **高召回率**意味着如果患者患有这种罕见疾病，则算法可能会正确识别出他们确实患有这种疾病



但在实践中，**精确率** 和 **召回率** 之间往往需要权衡取舍，例如：

![image-20240110163827409](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240110163827409.png)

在使用逻辑回归预测时，输出的值是 `[0,1]`之间的数值，如果想要输出类别，则需要指定**阈值**：

- **提高阈值**：如果我们想要只有在非常自信的时候才预测 $y=1$，则可以**提高阈值**：
  - 例如，选择 $threshold=0.7$ ，此时只有当输出 $f_{w,b} \ge 0.7$ 时才会预测 $y=1$，而 $f_{w,b} \lt 0.7$ 时预测 $y=0$
  - 则此时**精确率**会提高，因为无论何时预测，都更有可能是正确的，所以提高阈值会导致更高的**精确率**，
  - 但是它也会导致较低的**召回率**，因为 此时预测一个样本为正例会减少（则意味着 `TP`会减少），故召回率会降低
- **降低阈值**：如果想要避免遗漏预测正例，则可以**降低阈值**：
  - 例如，选择 $threshold=0.3$ ，此时只有当输出 $f_{w,b} \ge 0.3$ 时才会预测 $y=1$，而 $f_{w,b} \lt 0.3$ 时预测 $y=0$
  - 则此时**召回率**会提高，因为此时会预测更多患者患有该疾病（则意味着`TP`会增加），所以召回率会提高；

![image-20240110165621374](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240110165621374.png)

> **注意**：选择阈值并不是你可以通过交叉验证真正做到的事情，因为我们可以指定最佳点。
>
> 对于许多应用程序，手动选择阈值以权衡精度和召回率一般是我们要做的。



### `F1`分数

如果想要自动权衡精度和召回率而不是必须自己这样做，还有另一个指标为`F1`分数，有时用于自动结合精度和召回率以帮助你选择最佳价值或最佳两者之间的权衡。

`F1`分数是一种结合`P`和`R`精度和召回率的方法，但它更强调这些值中较低的那个。
$$
F1 \space score = \frac{1}{\frac{1}{2}(\frac{1}{P} + \frac{1}{R})}=2 \frac{PR}{P+R}
$$

> 在数学中，计算`F1`分数的方程也被称为 `P`和`R`的调和平均数，调和平均数是一种取平均值的方法，更强调较小的值。

