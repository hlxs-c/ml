# 有特征可供使用的推荐算法

符号说明：

1. $n_u$代表用户数量，$n_m$ 代表样本个数，$n$ 代代表特征数
2. $r(i, j) =1$ 如果用户 $j$ 已经给电影 $i$ 打分（0则没有）
3. $y(i,j)$ 是用户 $j$ 给电影$i$ 打的分（如果有的话）
4. $\mathbf{w}^{(j)}, b^{(j)}$ 是用户$j$ 的参数
5. $x^{(j)}$ 是电影 $i$ 的特征向量



## 1. 举例说明

假设我们有如下训练集，其中$x_1, x_2$ 是数据集的特征，而 $Alice(1)、Bob(2)$ 等列中的均为电影打分，视为标签：

![image-20240115130517910](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240115130517910.png)



### 1.1 定义模型

接下来我们看 **如何预测 Alice 对电影的评级**：使用**线性回归模型**：
$$
\text{For user 1:Predict rating for movie $i$ as: } \mathbf{w}^{(1)} · \mathbf{x}^{(i)} + b^{(1)}
$$
![image-20240115131040336](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240115131040336.png)

更一般地，在这个模型中，可以为用户 $j$ 预测其对电影 $i$ 的评分：
$$
\text{For user $j$ :Predict rating for movie $i$ as: } \mathbf{w}^{(j)} · \mathbf{x}^{(i)} + b^{(j)}
$$

### 1.2 定义损失函数（成本函数）

有如下定义：

1. $r(i, j) =1$ 如果用户 $j$ 已经给电影 $i$ 打分（0则没有）

2. $y(i,j)$ 是用户 $j$ 给电影$i$ 打的分（如果有的话）

3. $\mathbf{w}^{(j)}, b^{(j)}$ 是用户$j$ 的参数

4. $x^{(j)}$ 是电影 $i$ 的特征向量

5. $$
   \text{For user $j$ :Predict rating for movie $i$ as: } \mathbf{w}^{(j)} · \mathbf{x}^{(i)} + b^{(j)}
   $$

6. $m^{(j)}$ 代表用户$j$ 已经评分的电影的数量



**单个用户的成本函数**：
$$
J(\mathbf{w}^{(j)}, b^{(j)}) = \frac{1}{2m^{(j)}} \sum_{i:r(i,j)=1} (\mathbf{w}^{(j)}·x^{(i)} + b^{(j)} - y^{(i,j)})^2
$$
注意：由于用户还没有对所有电影进行评分，所以成本函数中使用 $\sum_{i:r(i,j)=1}$ 来对只进行评分过的电影的误差进行求和。

**加入正则化**：
$$
J(\mathbf{w}^{(j)}, b^{(j)}) = \frac{1}{2m^{(j)}} \sum_{i:r(i,j)=1} (\mathbf{w}^{(j)}·x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2m^{(j)}} \sum_{k=1}^n (w_k^{(j)})^2
$$
事实证明，对于推荐系统，实际上消除掉分母中的 $m^{(j)}$ 项也是可以的，因为 $m^{(j)}$ 只是该表达式中的一个常数，即：
$$
J(\mathbf{w}^{(j)}, b^{(j)}) = \frac{1}{2} \sum_{i:r(i,j)=1} (\mathbf{w}^{(j)}·x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{k=1}^n (w_k^{(j)})^2
$$
**所有用户的成本函数**：
$$
J(\mathbf{w}^{(1)},...,\mathbf{w}^{(n_u)}, b^{(1)},...,b^{(n_u)}) = \\ \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} (\mathbf{w}^{(j)}·x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^{n} (w_k^{(j)})^2
$$
这将是为所有用户学习所有参数的损失函数，如果我们使用 **梯度下降**或其他任何优化算法来最小化该成本函数，则将会得到一组比较好的参数用于预测所有用户对电影的评级。



这个算法看起来很像是一个线性回归，相当于我们为每个用户训练了一个线性回归模型。



