# 协同过滤推荐系统实践

在该实践中，将实现 **协同过滤** 以构建电影的推荐系统。



## 1. 推荐系统

在本实验中，我们将实现 **协同过滤学习算法**，并将其应用于电影评分数据集。

**协同过滤推荐系统** 的目标是生成两个向量：

- 对于每个用户，生成一个体现用户电影品味的 **参数向量**
- 对于每部电影，生成一个相同大小的 **特征向量** ，体现电影的某些特点

**`参数向量`和`特征向量`的点积加上`偏差项`得到用户给电影评分的预测值**。



下图详细介绍了如何学习这些向量：

![image-20240130110353489](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240130110353489.png)



一旦学习了 **特征向量** 和 **参数向量**，它们就可以用来预测用户如何评分未评分的电影，如下图所示，其预测了用户1在电影0上的评分：

![image-20240130110552242](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240130110552242.png)



在本实践·中，我们将实现用 **计算协同过滤目标函数（成本）的函数`cofiCostFunc`**。实现目标函数之后，将使用 `TensorFlow`自定义训练循环来学习协同过滤的参数。



## 2. 电影评分数据集

该电影评分数据集专注于自2000年以来的电影，该数据集由 `0.5-5`的评分组成，以`0.5`作为增量。

共包含 $n_u=443$ 位用户 和 $n_m=4778$ 部电影。



下面，我们将电影数据集加载到变量 $Y$ 和 $R$中，同时，在本部分联系中，我们还将使用矩阵 $\matrix{X}, \matrix{W}, \mathbf{b}$：

![image-20240130111114909](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240130111114909.png)

- $\matrix{X}$ 的第 $i$ 行对应于第 $i$ 部电影的特征向量
- $\matrix{W}$ 的第 $j$ 行对应于第 $j$ 个用户的参数向量
- $x^{(i)}, w^{(j)}$ 都是 $n$ 维向量，在本实践中，我们将使用 $n=10$，即 $x^{(i)}, w^{(j)}$ 都有10个元素，相应的，$\matrix{X}$ 是一个 $n_m \times 10$的矩阵，$\matrix{W}$ 是一个 $n_u \times 10$的矩阵



我们将从加载电影评分数据集开始，以了解数据的结构。我们将加载数据集到变量 $\matrix{Y}$ 和 $\matrix{R}$中，同时我们还将加载预先计算的 $\matrix{X, W}, \mathbf{b}$ 的值，这些预先计算的值用于开发成本模型：

```py
#Load data
X, W, b, num_movies, num_features, num_users = load_precalc_params_small()
Y, R = load_ratings_small()

# scan data
print("Y", Y.shape, "R", R.shape)
print("X", X.shape)
print("W", W.shape)
print("b", b.shape)
print("num_features", num_features)
print("num_movies",   num_movies)
print("num_users",    num_users)
```



## 3. 协同过滤学习算法

### 3.1 成本函数

实现 **协同过滤学习算法** ，首先将从实现 **成本目标函数** 开始：

电影推荐系统的协同过滤学习算法中考虑了一组 $n$ 维的参数向量：

- $$
- $\mathbf{w}^{(0)},...,\mathbf{w}^{(n_u-1)}, b^{(0)},...,b^{(n_u-1)}$

其中模型预测用户 $j$ 对电影 $i$ 的评分为： $y^{(i,j)} = \mathbf{w}^{(j)} · \mathbf{x}^{(i)} + b^{(i)}$。

给定一个由某些用户对某些电影的评分的数据集，我们希望学习参数向量 $\mathbf{x}^{(0)},...,\mathbf{x}^{(n_m-1)},\mathbf{w}^{(0)},...,\mathbf{w}^{(n_u-1)}, b^{(0)},...,b^{(n_u-1)} $ 以产生最佳拟合（最小化平方误差）。



下面我们将实现 `cofiCostFunc`函数，以计算用于协同过滤的成本函数：

协同过滤的成本函数由下式给出：
$$
J(\mathbf{x}^{(0)},...,\mathbf{x}^{(n_m-1)},\mathbf{w}^{(0)},...,\mathbf{w}^{(n_u-1)}, b^{(0)},...,b^{(n_u-1)} ) = \\
\frac{1}{2} \sum_{(i,j):r(i,j)=1} (\mathbf{w}^{(j)}·\mathbf{x}^{(i)}+b^{(j)}-y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{j=0}^{n_u-1} \sum_{k=0}^{n-1}(\mathbf{w}_k^{(j)})^2 + \frac{\lambda}{2}\sum_{i=0}^{n_m-1}\sum_{k=0}^{n-1}(\mathbf{x}_k^{(i)})^2 
\tag{1}
$$
上式即：
$$
J(\mathbf{x}^{(0)},...,\mathbf{x}^{(n_m-1)},\mathbf{w}^{(0)},...,\mathbf{w}^{(n_u-1)}, b^{(0)},...,b^{(n_u-1)} ) = \\
\frac{1}{2} \sum_{(i,j):r(i,j)=1} (\mathbf{w}^{(j)}·\mathbf{x}^{(i)}+b^{(j)}-y^{(i,j)})^2 + regularization
\tag{2}
$$


#### `for`循环版本

```py
# cofi_cost_func

def cofi_cost_func(X, W, b, Y, R, lambda_):
    """
    Returns the cost for the content-based filtering
    Args:
    	X(ndarray(num_movies, num_features)):	matrix of item features
    	W(ndarray(num_users, num_features)):	matrix of user parameters
    	b(ndarray(1, num_users)):				vector of user parameters
    	Y(ndarray(num_movies, num_users)):	matrix of user ratings of movies
    	R(ndarray(num_movies, num_users)):	matrix,where R(i,j)=1 if the i-th movies was rated by the j-th user
    	lambda_(float):						regularization parameter
    
    Returns:
    	J(float):	Cost
    """
    n_m, n_u = Y.shape
    J = 0
    # 遍历所有用户
    for j in range(nu):
        # 取得用户 j 的参数向量
        w = W[j, :]
        b_j = b[0, j]
        # 遍历所有电影：
        for i in range(nm):
            # 取得电影 i 的特征向量
            x = X[i, :]
            # 取得电影 i 的评分（目标值）
            y = Y[i, j]
            r = R[i, j]
            # 加上该电影的损失（如果 r=1的话，即该电影已经有评分（目标值））
            J += np.square(r * (np.dot(w, x) + b_j - y))
	# 加上正则化项
    J += lambda_ * (np.sum(np.square(W)) + np.sum(np.square(X)))
    J = J/2
    
    return J
```



#### 向量化实现

```py
def cofi_cost_func_v(X, W, b, Y, R, lambda_):
    """
    Returns the cost for the content-based filtering
    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.
    Args:
      X (ndarray (num_movies,num_features)): matrix of item features
      W (ndarray (num_users,num_features)) : matrix of user parameters
      b (ndarray (1, num_users)            : vector of user parameters
      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies
      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user
      lambda_ (float): regularization parameter
    Returns:
      J (float) : Cost
    """
    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y) * R
    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))
    return J
```



## 4. 学习电影推荐

完成实现协同过滤成本函数之后，就可以开始训练算法为自己推荐电影：



首先，我们可以输入自己的电影选择（即给数据集中含有的某些电影进行评分），然后算法将为我们提出建议：

```py
movieList, movieList_df = load_Movie_List_pd()

my_ratings = np.zeros(num_movies)          #  Initialize my ratings

# Check the file small_movie_list.csv for id of each movie in our dataset
# For example, Toy Story 3 (2010) has ID 2700, so to rate it "5", you can set
my_ratings[2700] = 5 

#Or suppose you did not enjoy Persuasion (2007), you can set
my_ratings[2609] = 2;

# We have selected a few movies we liked / did not like and the ratings we
# gave are as follows:
my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The
my_ratings[246]  = 5   # Shrek (2001)
my_ratings[2716] = 3   # Inception
my_ratings[1150] = 5   # Incredibles, The (2004)
my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)
my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)
my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)
my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)
my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)
my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)
my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)
my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]

print('\nNew user ratings:\n')
for i in range(len(my_ratings)):
    if my_ratings[i] > 0 :
        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,"title"]}');
```



然后，我们将我们自己的评分数据加入到 $Y$ 和 $R$ 中，并进行**标准化**：

```py
# Reload ratings and add new ratings
Y, R = load_ratings_small()
Y    = np.c_[my_ratings, Y]
R    = np.c_[(my_ratings != 0).astype(int), R]

# Normalize the Dataset
Ynorm, Ymean = normalizeRatings(Y, R)
```



开始训练模型：

- 初始化参数
- 选择 `Adam` 优化器

```py
#  Useful Values
num_movies, num_users = Y.shape
num_features = 100

# Set Initial Parameters (W, X), use tf.Variable to track these variables
tf.random.set_seed(1234) # for consistent results
W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')
X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')
b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')

# Instantiate an optimizer.
optimizer = keras.optimizers.Adam(learning_rate=1e-1)
```



接着，我们开始训练协同过滤模型，以学习参数 $\matrix{X,W}, \mathbf{b}$：

由于同时学习 $\matrix{X,W}, \mathbf{b}$ 这些参数的操作不属于 TensorFlow 神经网络中提供的典型 `层`。因此，我们需要使用自定义训练循环。

梯度下降的步骤：

```
重复以下步骤直到收敛：
	计算前向结果
	计算损失相对于参数的导数
	使用学习率和计算出来的导数更新参数
```



```py
iterations = 200
lambda_ = 1
for iter in range(iterations):
    # Use TensorFlow's GradientTape
    # to record the operations used to compute the cost
    with tf.GradientTape() as tape:
        # Compute the cost (forward pass included in cost)
        cost_value = cofi_cost_func(X, W, b, Ynorm, R, lambda_)
   	
    # Use the gradient tape to automatically retrieve
    # the gradients of the trainable variables with respect to the loss
    grads = tape.gradient( cost_value, [X, W, b] )
    
    # Run one step of gradient descent by updating
    # the value of the variables to minimize the loss
    optimizer.apply_gradients( zip(grads, [X, W, b]))
    
    # Log periodically:
    if iter %20 == 0:
        print(f"Training loss at iteration {iter} : {cost_value:0.1f}")
```



## 5. 电影推荐的建议（使用模型）

下面，我们计算所有用户对所有电影的评分，并显示推荐的电影。这些是基于 `my_ratings[]`中输入的电影和评分进行的。

要预测用户 $j$ 对电影 $i$ 的评分，需要计算 $\mathbf{w}^{(j)}· \mathbf{x}^{(i)} + b^{(j)}$， 这可以使用矩阵乘法计算所有评分：

```py
# Make a prediction using trained weights and biases
p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()

#restore the mean
pm = p + Ymean

my_predictions = pm[:,0]

# sort predictions
ix = tf.argsort(my_predictions, direction='DESCENDING')

for i in range(17):
    j = ix[i]
    if j not in my_rated:
        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')

print('\n\nOriginal vs Predicted ratings:\n')
for i in range(len(my_ratings)):
    if my_ratings[i] > 0:
        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')
```

