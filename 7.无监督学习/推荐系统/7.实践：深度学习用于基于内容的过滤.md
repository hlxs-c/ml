# 实践：深度学习用于基于内容的过滤

在本实践中，我们将使用神经网络实现基于内容的过滤，以构建电影的推荐系统。



## 1. 使用神经网络进行基于内容的过滤

在 **协同过滤学习算法** 中，我们生成了两个向量，一个是**用户的参数向量**，一个是**电影的特征向量**，通过这两个向量的点积，加上偏差项，以生成电影的预测评分。



**基于内容的过滤** 也会生成用户和电影的特征向量，但是会识别处可能存在有关用户和/或电影的其他可用信息，这些信息可能会改进预测。附加信息被提供给神经网络，然后神经网络生成用户和电影向量，如下所示：

![image-20240130121330539](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240130121330539.png)

提供给神经网络的电影的输入 $x_m$ 是原始特征和一些特征工程得到的特征的组合。例如，原始特征是电影的 `上映年份` 和 `电影类型`，特征工程生成的特征是 `所有用户对该电影的平均评分`。

提供给神经网络的用户的输入 $x_u$ 都是通过特征工程生成的特征。例如，对于每种类型电影的平均评分。



## 2. 数据集

### 2.1 加载数据集以及对数据集进行分析描述

```py
# Load Data, set configuration variables
item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()

num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training
num_item_features = item_train.shape[1] - 1  # remove movie id at train time
uvs = 3  # user genre vector start
ivs = 3  # item genre vector start
u_s = 3  # start of columns to use in training, user
i_s = 1  # start of columns to use in training, items
scaledata = True  # applies the standard scalar to data if true
print(f"Number of training vectors: {len(item_train)}")
```

上述代码将加载数据到变量中，下面对代码中的变量进行解释说明，以更好地理解数据集：

- `item_features` 是 电影的特征说明向量（元数据），如下所示：
  - ![image-20240131113314367](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131113314367.png)
  - 电影`id`，年份，所有用户对该电影的平均评分，电影所属类别的独热编码（即如果一部电影是动作电影，则其`Action`对应的列的值为1，其余列为0），注意，如果一部电影属于多个类别，则这个电影会有多个特征向量（存储在`item_train`中），前三个值相同，而独热编码中为1的列不同，例如：
    - ![image-20240131113643197](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131113643197.png)
    - 如上所示，id为`6874`的电影的年份为`2003`，所有用户对其的平均评分为 `3.961...`，其属于三个类别，所以在训练集中有3个特征向量用于表示该电影，这三个特征向量的独热编码为1的列不同
  - **注意**：由于训练时不需要电影的`id`作为特征（因为其与评分无关，加入训练会影响模型），故在计算电影的特征的个数（维数）时需要减去1
- `item_train` 是每部电影的特征向量组合而成的矩阵，其中，每一列对应于`item_features`中的每一列：
  - ![image-20240131113844712](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131113844712.png)
- `user_features` 是 用户的特征说明向量（元数据）：
  - ![image-20240131113933500](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131113933500.png)
  - 用户`id`，总共评分了多少电影，其给出的评分的平均值，对每种类型的电影的平均评分
  - ![image-20240131114317696](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131114317696.png)
    - 上述数据表示：用户`id`为2，共评分了16部电影，给出的平均评分为`4.0625`，接下来是其对每种类型电影的平均评分
- `user_train` 是每个用户的特征向量组合而成的矩阵
- `y_train[i]` 是 `user_train[i]`代表的用户对 `item_train[i]`代表的电影的评分
- `item_vecs` 是所有电影的特征向量组合而成的矩阵（**没有重复**）
  - **注意**：`item_vecs`和`item_train`是不同的，因为`item_train`中一部电影可能会有多组特征向量（因为可能有多个用户对该部电影进行评分），但是在`item_vecs`中，每一部电影只会有一组特征向量，之后用于新用户对所有电影进行评分预测。
- `movie_dict`是电影`id`和电影名字的字典
- `user_to_genre`是用户`id`以及其对应喜欢的电影类型





![image-20240131114717015](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131114717015.png)

- 如上所示，`user_train[0],user_train[1],user_train[2]` 都代表`用户2`，对`item_train[0],item_train[1],item_train[2]`代表的`电影6874`的评分为 `y_train[0],y_train[1],y_train[2]`都为4。
- 同时，注意到，`user_train`中还有很多代表`用户2`的相同的特征向量，即代表`用户2`对其他电影进行评分是训练数据
- 同时，`item_train`中也还有其他同样代表`电影6874`的相同的一组特征向量，代表还有其他用户对该电影进行了评分



对加载到变量中的数据集进行打印展示：

```py
# pprint_train 为自定义函数，用于将数据打印输出成表格的形式
pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)

pprint_train(item_train, item_features, ivs, i_s, maxcount=5, user=False)

print(f"y_train[:5]: {y_train[:5]}")
```

![image-20240131115651306](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131115651306.png)

![image-20240131115703040](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131115703040.png)

![image-20240131115711542](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131115711542.png)



综上所述：

- 输入到`用户神经网络` 的训练数据集为 `user_train`，其代表的是每个用户的特征向量组合而成的矩阵，且输入到神经网络中的数据从`user_train`中的第4列开始，因为前3列不作为用户的特征（对评分预测无用），即真正输入到神经网络中的数据为`user_train[ : , 3: ]`
- 输入到`电影神经网络` 的训练数据集为`item_train`，其代表的是每部电影的特征向量组合而成的矩阵，且输入到神经网络中的数据从`item_train`中的第2列开始，因为第1列的电影`id`不作为电影的特征（对评分预测无用），即真正输入到神经网络中的数据为`item_train[ : , 1:]`



### 2.2 预处理数据

#### 2.2.1 特征缩放——改进收敛性

使用特征缩放，将所有特征的取值范围统一到一个相似的范围，从而可以加快训练速度以及收敛性。

以下我们使用`scikit`库中的`StandardScaler`来进行特征缩放：

```py
# scale training data
if scaledata:
    item_train_save = item_train
    user_train_save = user_train

    scalerItem = StandardScaler()
    scalerItem.fit(item_train)
    item_train = scalerItem.transform(item_train)

    scalerUser = StandardScaler()
    scalerUser.fit(user_train)
    user_train = scalerUser.transform(user_train)

    print(np.allclose(item_train_save, scalerItem.inverse_transform(item_train)))
    print(np.allclose(user_train_save, scalerUser.inverse_transform(user_train)))
```



#### 2.2.2 数据集拆分——拆分为`训练集`和`测试集`

为了评估模型结果，我们需要将数据拆分为`训练集`和`测试集`。

以下，我们将使用`sklearn`库中的`sklearn_train_test_split`来拆分和随机打乱数据。

但是需要**注意**：因为`user_train[i]`和`item_train[i]`以及`y_train[i]` 是一一对应的，所以随机打乱数据以及拆分数据集时需要注意保证数据的这一特点，否则将使数据集无用。这可以通过将初始的随机状态设置为相同的值来确保`item_train、user_train、y_train`随机打乱之后的随机排列相同，即保证它们的一一对应关系不变。

```py
item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)
user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)
y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)
print(f"movie/item training data shape: {item_train.shape}")
print(f"movie/item test  data shape: {item_test.shape}")
```

![image-20240131120916285](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131120916285.png)



#### 2.2.3 对目标值进行特征缩放

使用`最小-最大缩放器` 对目标值进行特征缩放，将其缩放到`[-1,1]`之间。

以下我们使用`scikit-learn`进行缩放，因为它含有一个`inverse_transform`可以逆转换，比较方便：

```py
scaler = MinMaxScaler((-1, 1))
scaler.fit(y_train.reshape(-1, 1))
ynorm_train = scaler.transform(y_train.reshape(-1, 1))
ynorm_test = scaler.transform(y_test.reshape(-1, 1))
print(ynorm_train.shape, ynorm_test.shape)
```



## 3. 用于`基于内容的过滤`的神经网络

### 3.1 构建网络

接下来，我们将构建一个神经网络，如图1所示，它含有两个网络，由一个点积组合在一起。

在该实践中，我们将`用户神经网络`和`电影神经网络`构建为相同的，但注意这两个网络不必相同，如果用户内容远远大于电影内容，则可以选择增加用户网络的复杂性。但在该实践中，用户和电影的内容相似，故网络可以构建为相同的。

使用`Keras`的顺序模型构建用户神经网络和电影神经网络：

- 第一层是具有256个单元和`relu`激活函数的全连接层
- 第二层是具有128个单元和`relu`激活函数的全连接层
- 第三层是具有`num_outputs`个单元和`linear`激活函数的全连接层

网络的其余部分将使用`Keras`提供的`API`，将用户神经网络和电影神经网络通过点积互联在一起：

```py
# GRADED_CELL
# UNQ_C1

num_outputs = 32
tf.random.set_seed(1)
user_NN = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(num_outputs, activation='linear')
])

item_NN = tf.keras.models.Sequential([   
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(num_outputs, activation='linear')
])

# create the user input and point to the base network
input_user = tf.keras.layers.Input(shape=(num_user_features))
vu = user_NN(input_user)
vu = tf.linalg.l2_normalize(vu, axis=1)

# create the item input and point to the base network
input_item = tf.keras.layers.Input(shape=(num_item_features))
vm = item_NN(input_item)
vm = tf.linalg.l2_normalize(vm, axis=1)

# compute the dot product of the two vectors vu and vm
output = tf.keras.layers.Dot(axes=1)([vu, vm])

# specify the inputs and output of the model
model = Model([input_user, input_item], output)

model.summary()
```



### 3.2 编译网络

我们将使用`均方误差损失`和`Adam`优化器：

```py
tf.random.set_seed(1)
cost_fn = tf.keras.losses.MeanSquaredError()
opt = keras.optimizers.Adam(learning_rate=0.01)
model.compile(optimizer=opt,
              loss=cost_fn)
```



### 3.3 训练网络

```py
tf.random.set_seed(1)
model.fit([user_train[:, u_s:], item_train[:, i_s:]], ynorm_train, epochs=30)
```

![image-20240131121955546](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131121955546.png)



### 3.4 评估模型

评估模型以确定`测试数据`（测试集）的损失：

```py
model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], ynorm_test)
```

![image-20240131122006222](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131122006222.png)

可以看到，`测试集`的损失和`训练集`最终的损失相差不多，表明模型没有过拟合训练数据。



### 3.5 使用模型进行预测

接下来，我们将使用上述经过训练的模型在多种情况下进行预测：



#### 3.5.1 针对新用户对电影评分的预测

要预测新用户对电影评分，有以下几个步骤：

1. 创建一个新的用户向量，代表该用户的特征向量
2. 将该用户向量复制形成一个矩阵（`user_vecs`），其大小与电影（物品）矩阵（`item_vecs`）的大小相同，以使得具有一一对应关系，即每个电影向量都有对应的用户向量与之对应
3. 将用户矩阵（`user_vecs`）输入到模型中的用户神经网络，电影矩阵（`item_vecs`）输入到模型中的电影神经网络，进行推理，然后得到`vu`和`vm`矩阵，最好经过模型的最后一步（点积）得到`user_vecs[i]`对`item_vecs[i]`的评分，则可以得到该新用户对所有电影的预测评分数据：
   - **注意**：由于我们的模型在构建和训练时，输入的数据`user_train`和`item_train`都是经过特征缩放的，所以在进行推理时，也需要对新的输入进行特征缩放，且必须使用用于训练集的缩放器进行缩放：
     - `user_vecs`使用缩放`user_train`的缩放器`scalerUser`
     - `item_vecs`使用缩放`item_train`的缩放器`scalerItem`
     - 因为`scalerUser`和`scalerItem`记录了对`user_train`和`item_train`进行缩放的值（平均值、方差等）
   - 同时，训练时对目标值也进行了特征缩放，则模型的最终输出是经过特征缩放的输出，故也需要将该缩放器（`scaler`）提供给包含所有推理步骤的函数，因为`scaler`中有函数`inverse_transform()`，可以将进行特征缩放的输出进行逆变换，得到真正的预测评分数据



##### （1）创建新用户的特征向量

![image-20240131122213286](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131122213286.png)

首先，我们将创建一个新用户，并让模型为该用户推荐电影：

```py
new_user_id = 5000
new_rating_ave = 1.0
new_action = 1.0
new_adventure = 1
new_animation = 1
new_childrens = 1
new_comedy = 5
new_crime = 1
new_documentary = 1
new_drama = 1
new_fantasy = 1
new_horror = 1
new_mystery = 1
new_romance = 5
new_scifi = 5
new_thriller = 1
new_rating_count = 3

user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,
                      new_action, new_adventure, new_animation, new_childrens,
                      new_comedy, new_crime, new_documentary,
                      new_drama, new_fantasy, new_horror, new_mystery,
                      new_romance, new_scifi, new_thriller]])
```



##### （2）复制新用户向量形成用户特征矩阵（`user_vecs`）

```py
def gen_user_vecs(user_vec, num_items):
    """ given a user vector return:
        user predict maxtrix to match the size of item_vecs
        
        这段代码的作用是生成用户预测矩阵（user predict matrix），该矩阵的大小与物品向量矩阵（item_vecs）相匹配。
        具体而言，该函数接收一个用户向量（user_vec）和物品数量（num_items）作为输入。然后使用numpy库的tile函数将用户向量复制（tile）成一个新的矩阵，使其行数与物品数量（num_items）相同。在复制过程中，用户向量的每个元素将被复制到新矩阵的每一行上。
        这样，函数泛化的用户预测矩阵（user_vecs）将具有与物品向量矩阵相同的行数，但每一行都是相同的用户向量。
        总结起来，该函数的目的是生成一个与物品向量矩阵（item_vecs）大小相匹配的用户向量矩阵，其中用户向量矩阵中所有向量都相同，代表同一个用于，将输入到模型中，用于预测该用户对所有物品的评分。
        """
    user_vecs = np.tile(user_vec, (num_items, 1))
    return(user_vecs)

```



```py
# generate and replicate the user vector to match the number movies in the data set.
user_vecs = gen_user_vecs(user_vec,len(item_vecs))
```



##### （3）输入到模型中进行推理预测

```py
# predict on  everything, filter on print/use
def predict_uservec(user_vecs, item_vecs, model, u_s, i_s, scaler, ScalerUser, ScalerItem, scaledata=False):
    """ given a user vector, does the prediction on all movies in item_vecs returns
        an array predictions sorted by predicted rating,
        arrays of user and item, sorted by predicted rating sorting index
    """
    if scaledata:
        scaled_user_vecs = ScalerUser.transform(user_vecs)
        scaled_item_vecs = ScalerItem.transform(item_vecs)
        y_p = model.predict([scaled_user_vecs[:, u_s:], scaled_item_vecs[:, i_s:]])
    else:
        y_p = model.predict([user_vecs[:, u_s:], item_vecs[:, i_s:]])
    y_pu = scaler.inverse_transform(y_p)

    if np.any(y_pu < 0) : 
        print("Error, expected all positive predictions")
    sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first
    sorted_ypu   = y_pu[sorted_index]
    sorted_items = item_vecs[sorted_index]
    sorted_user  = user_vecs[sorted_index]
    return(sorted_index, sorted_ypu, sorted_items, sorted_user)
```

这部分代码的作用是根据给定的用户向量矩阵，在物品向量矩阵上进行预测，并返回按预测评分排序的预测结果。

函数的输入包括用户向量矩阵（`user_vecs`），物品向量矩阵（`item_vecs`）、模型（`model`）、用户特征索引（`u_s`，用于排除不输入到网络中的特征），物品特征索引（`i_s`），对训练集中目标值进行特征缩放的缩放器（`scaler`），对训练集中用户特征矩阵（`user_train`）和物品特征矩阵（`item_train`）进行特征缩放的缩放器（`ScalerItem`、`ScalerUser`），以及一个布尔值参数（`scaledata`，用于表示是否训练模型时是否进行过特征缩放）。

- 首先，根据参数`scaledata`的值，函数会选择是否对输入数据进行缩放：
  - 如果`scaledata`为True，那么用户向量矩阵和物品向量矩阵分别会通过对应的缩放器（`ScaleUer`、`ScaleItem`）进行特征缩放
- 然后，使用模型对缩放后的用户向量和物品向量进行预测，得到预测结果`y_p`
- 接下来，将预测结果`y_p`通过逆转换（`inverse_transform`）操作，将其从缩放后的范围还原会原始范围。这样得到的预测结果`y_pu`表示用户对各个物品的评分预测。
  - 因为训练模型时，输入的目标值是经过特征缩放的，所以模型的输出是经过特征缩放的范围，则推理时需要将模型的输出进行逆转换，以还原到原始范围。
- 如果预测结果中存在小于0的评分，则会打印错误信息，因为预期的评分应该都是正数。
- 然后，根据预测评分`y_pu`的降序排列，得到对应的排序索引`sorted_index`，并将预测评分、物品向量和用户向量按照排序索引进行排序。
  - **注意**：不能直接对预测评分`y_pu`进行排序，因为`user_vecs[i]`、`item_vecs[i]`和`y_pu[i]`之间是一一对应关系的，如果直接对`y_pu`进行排序，则会打乱这种对应关系，则我们就不知道哪一个评分是`user_vecs[i]`对`item_vecs[i]`给出的。
    - 所以，应该先根据预测评分`y_pu`的降序排序得到对应的排序索引`sorted_index`，然后再使这三者按照这个排序索引进行排序，因为索引是一一对应的。
- 返回排序索引，排序后的预测评分，排序后的物品向量和排序后的用户向量。

这段代码的作用是根据用户向量对所有物品进行评分预测，并将结果按照预测评分进行排序，以便后续可以根据评分高低进行推荐或其他相关操作。



```py
# scale the vectors and make predictions for all movies. Return results sorted by rating.
sorted_index, sorted_ypu, sorted_items, sorted_user = predict_uservec(user_vecs,  item_vecs, model, u_s, i_s, 
                                                                       scaler, scalerUser, scalerItem, scaledata=scaledata)

print_pred_movies(sorted_ypu, sorted_user, sorted_items, movie_dict, maxcount = 10)
```

调用`predict_uservec`函数，进行预测，并输出新用户预测评分最高的前10部电影：

![image-20240131144930172](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131144930172.png)



综上所述，在经过训练之后，给定包含用户对每种类型电影的评分的用户特征向量，该模型可以预测该用户对所有电影的评分，但是如果没有这样的特征向量，则可能预测结果没有意义。



#### 3.5.2 针对现有用户对电影评分的预测

针对先后有用户对电影评分的预测有以下步骤：

- 同样的，也需要获得获得该用户的特征向量
- 然后根据该用户的特征向量创建该用户的特征矩阵
- 将用户特征矩阵以及电影特征矩阵输入到模型中进行预测



##### （1）获得该用户的特征矩阵

```py
def get_user_vecs(user_id, user_train, item_vecs, user_to_genre):
    """ given a user_id, return:
        user train/predict matrix to match the size of item_vecs
        y vector with ratings for all rated movies and 0 for others of size item_vecs """

    if user_id not in user_to_genre:
        print("error: unknown user id")
        return(None)
    else:
        user_vec_found = False
        for i in range(len(user_train)):
            if user_train[i, 0] == user_id:
                user_vec = user_train[i]
                user_vec_found = True
                break
        if not user_vec_found:
            print("error in get_user_vecs, did not find uid in user_train")
        num_items = len(item_vecs)
        user_vecs = np.tile(user_vec, (num_items, 1))

        y = np.zeros(num_items)
        for i in range(num_items):  # walk through movies in item_vecs and get the movies, see if user has rated them
            movie_id = item_vecs[i, 0]
            if movie_id in user_to_genre[user_id]['movies']:
                rating = user_to_genre[user_id]['movies'][movie_id]
            else:
                rating = 0
            y[i] = rating
    return(user_vecs, y)
```

这段代码的作用是根据给定的用户ID，在用户训练数据（`user_train`）、物品向量矩阵（`item_vecs`）和用户到电影类别的映射（`user_to_genre`）中获取用户向量和评分信息。

函数的输入包括用户ID（user_id）、用户训练数据（`user_train`）、物品向量矩阵（`item_vecs`）和用户到电影类别的映射（`user_to_genre`）。

首先，函数会检查给定的用户ID是否存在于用户到电影类别的映射中。如果用户ID不存在于映射中，会打印错误信息并返回None。否则，会通过遍历用户训练数据，找到与给定用户ID匹配的用户向量（`user_vec`）。

接下来，函数会根据物品向量矩阵的大小，使用`NumPy`库的`tile`函数将用户向量复制成一个新的矩阵，使其行数与物品向量矩阵的行数相同。这样生成的用户矩阵（`user_vecs`）与物品向量矩阵具有相同的行数，但每一行都是相同的用户向量。

然后，函数会创建一个长度为物品向量矩阵行数的零向量y，并逐个遍历物品向量矩阵中的电影。对于每个电影，函数会检查用户是否对该电影进行了评分，如果是，则将相应的评分赋值给y向量的相应位置；如果否，则将评分设为0。

最后，函数返回生成的用户矩阵（`user_vecs`）和评分向量`y`，这些向量可以用于用户对电影评分的预测或其他相关计算。

总结起来，这段代码的作用是根据给定的用户ID获取用户向量和评分信息，以便进行用户对电影的评分预测和其他相关计算。



##### （2）预测

```py
uid =  36 
# form a set of user vectors. This is the same vector, transformed and repeated.
user_vecs, y_vecs = get_user_vecs(uid, scalerUser.inverse_transform(user_train), item_vecs, user_to_genre)

# scale the vectors and make predictions for all movies. Return results sorted by rating.
sorted_index, sorted_ypu, sorted_items, sorted_user = predict_uservec(user_vecs, item_vecs, model, u_s, i_s, scaler, 
                                                                      scalerUser, scalerItem, scaledata=scaledata)
sorted_y = y_vecs[sorted_index]

#print sorted predictions
print_existing_user(sorted_ypu, sorted_y.reshape(-1,1), sorted_user, sorted_items, item_features, ivs, uvs, movie_dict, maxcount = 10)
```

![image-20240131152034560](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131152034560.png)



#### 3.5.4 查找相似项目

经过训练的神经网络会生成两个特征向量：

- 一个是用户特征向量$V_u$
- 一个是电影特征向量$V_m$
- 这两个向量都具有32个元素，元素的值代表的意义很难解释，但是，相似的项目将具有相似的向量（因为经过相同的模型），利用该信息可以提出一些建议。
  - 例如，如果用户对《玩具总动员3》的评价很高，则可以通过选择具有相似电影特征向量的电影来推荐类似的电影。

**相似度度量** 是两个向量之间的平方距离：
$$
||\mathbf{v}_m^{(k)} - \mathbf{v}_m^{(i)}|| = \sum_{l=1}^{n}(\mathbf{v}_{m_l}^{(k)} - \mathbf{v}_{m_l}^{(i)})
$$
编写函数来计算上述中的平方距离，即**计算两个向量的相似度**：

```py
# GRADED_FUNCTION: sq_dist
# UNQ_C2
def sq_dist(a,b):
    """
    Returns the squared distance between two vectors
    Args:
      a (ndarray (n,)): vector with n features
      b (ndarray (n,)): vector with n features
    Returns:
      d (float) : distance
    """    
    d = np.sum((a-b)**2)   
    return (d)
```





```py
input_item_m = tf.keras.layers.Input(shape=(num_item_features))    # input layer
vm_m = item_NN(input_item_m)                                       # use the trained item_NN
vm_m = tf.linalg.l2_normalize(vm_m, axis=1)                        # incorporate normalization as was done in the original model
model_m = Model(input_item_m, vm_m)                                
model_m.summary()
```

在模型训练之后，我们可以计算电影之间的距离矩阵，并在后续的推荐过程中重复使用该距离矩阵，而无需重新训练矩阵。

首先，在模型训练完成后，我们需要获取每个电影的特征向量$\mathbf{v}_m$，为了实现这一目的，可以使用已经训练好的 `item_NN`模型，并构建一个小的模型来运行电影向量（即将`item_vec`作为输入），并生成其对应的 $\mathbf{v}_m$。

具体而言，代码中使用 `input_item_m`定义了一个输入层，表示电影特征向量的输入。然后通过`item_NN`模型对输入的电影特征向量进行处理，得到处理后的特征向量$\mathbf{vm}_m$。接着，通过`tf.linalg.l2_normalize`对`vm_m` 进行`L2`归一化处理，以确保特征向量的长度一致。

最后，代码通过创建一个新的模型`model_m`，将`input_item_m`作为输入，将经过处理和归一化的特征向量`vm_m`作为输出（实际上就是将输入层和 `item_NN`串联组合在一起），这样，我们就可以使用`model_m`来运行电影原始特征向量，生成处理后的特征向量$\mathbf{v}_m$



在拥有电影模型之后，可以将一组电影原始特征向量作为输入，然后使用该模型生成一组电影特征向量。而`item_vecs` 是所有电影原始特征向量的集合（矩阵），所以可以将其作为该模型的输入，然后输出所有电影经过处理后的特征向量的集合（矩阵）。

**注意**：电影模型在训练时（即`item_NN`在训练时）是使用了特征缩放的，所以使用该模型进行推理时也应该对输入进行特征缩放，最终输出才是正确的经过处理后的特征向量矩阵$\matrix{V}_m$

```py
scaled_item_vecs = scalerItem.transform(item_vecs)
vms = model_m.predict(scaled_item_vecs[:,i_s:])
print(f"size of all predicted movie feature vectors: {vms.shape}")
```

![image-20240131154956445](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131154956445.png)



在计算得到所有电影的处理后的特征向量$\mathbf{v}_m$ 之后，就可以计算每个电影特征向量和所有其他电影特征向量之间的平方距离（相似度）矩阵：

![image-20240131155052645](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240131155052645.png)

然后，我们可以通过找到每行的最小值来找到最接近的电影：

```py
count = 50
dim = len(vms)
dist = np.zeros((dim,dim))

for i in range(dim):
    for j in range(dim):
        dist[i,j] = sq_dist(vms[i, :], vms[j, :])
        
m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0]))  # mask the diagonal

disp = [["movie1", "genres", "movie2", "genres"]]
for i in range(count):
    min_idx = np.argmin(m_dist[i])
    movie1_id = int(item_vecs[i,0])
    movie2_id = int(item_vecs[min_idx,0])
    genre1,_  = get_item_genre(item_vecs[i,:], ivs, item_features)
    genre2,_  = get_item_genre(item_vecs[min_idx,:], ivs, item_features)

    disp.append( [movie_dict[movie1_id]['title'], genre1,
                  movie_dict[movie2_id]['title'], genre2]
               )
table = tabulate.tabulate(disp, tablefmt='html', headers="firstrow", floatfmt=[".1f", ".1f", ".0f", ".2f", ".2f"])
table
```

