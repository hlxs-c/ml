# `K-means` 聚类算法

## 1.`K-means`算法的直观理解

![image-20240113113018743](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113113018743.png)

如上图所示，在图中绘制了一个包含30个未标记训练样本的数据集，并在该数据集上运行 `K-means`算法，并且要求它找到两个集群。

- `K-means` 算法做的第一件事是随机猜测我们可能要求它找到的两个聚类的中心位置

  - 它会随机选择两个点，猜测它们为两个集群的中心，如下图所示：
    - <img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113113321892.png" alt="image-20240113113321892" style="zoom:33%;" />
    - 上图中的猜测并不是一个很好的猜测，但这是`k-means`初始会做的事情

- 接下来 `K-means` 会重复做两件不同的事情：

  1. 将点分配给簇的质心：
     - 遍历这些点中的每一个，并查看它更接近哪一个中心点，然后`K-means`会将这些点中的每一个分配给它更接近的集群质心
     - <img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113114637011.png" alt="image-20240113114637011" style="zoom: 33%;" />
  2. 移动簇的质心：
     - 遍历所有簇，计算每个簇内所有样本的平均位置，并移动簇的质心到每个簇的平均位置，即以每个簇的平均位置作为新的质心
     - <img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113114749893.png" alt="image-20240113114749893" style="zoom:33%;" />
     - <img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113114804396.png" alt="image-20240113114804396" style="zoom:33%;" />

  事实证明，如果重复这两个步骤，即 **查看每个点并将其分配给最近的聚类质心**，然后**将每个聚类质心移动到在同一个聚类的所有点的平均位置**，直到 **点所在的聚类 或者 簇的质心没有更多的变化**，则说明此时 `K-means`算法已经收敛。

  因为一遍又一遍地应用这两个步骤，不会导致指向质心的分配或集群的质心的位置发生进一步变化。

  ![image-20240113114952158](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113114952158.png)



`K-means`算法的工作原理中，两个关键步骤是：

1. 将每个点分配给簇质心
2. 将每个簇质心移动到分配给它的所有点的平均值



## 2. `K-means`算法

![image-20240113121833296](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113121833296.png)

`K-means`算法的过程：

1. 随机初始化 $k$ 个集群（簇）的质心（中心点）：$ \mu_1, \mu_2,  \cdots, \mu_k$
2. 重复执行以下两个步骤：
   1. **将点分配给簇的质心**：
      - 遍历每一个$x^{(i)}$，计算出距离每个样本最近的簇的质心的索引 $c^{(i)}$
      - 从数学的角度出发，我们可以计算 $x^{(i)}$ 与 $\mu_k$ 之间的距离：$||x^{(i)} - \mu_k||$，它也被称为 $L2$ 范数，然我我们需要找到可以最小化这个值的 $k$ 值，即 $min_k(||x^{(i)} - \mu_k||)$，从而找到最接近训练样本 $x^{(i)}$ 的簇质心 $\mu_k$；
      - 在实现这个算法时，最小化距离的平方实际上会更方便一些，因为通过最小化距离的平方和最小化距离得到的最近的簇质心是相同的，而距离的平方不需要进行开方计算更加容易计算，故一般使用 $min_k(||x^{(i)} - \mu_k||^2)$
   2. **移动簇的质心到分配给它的所有点的平均值，即更新集群的质心位置为分配给该集群的所有点的平均值：**
      - 遍历每一个集群（簇）$cluster_k$，计算分配到该集群中的所有点的平均值$mean(cluster_k)$，更新 $\mu_k = mean(cluster_k)$
      - 计算平均值的方法：$mean(cluster_k) = \frac{\sum_j x^{(j)}}{m_k}$
      - 可能会出现一种**极端情况**：如果一个集群中分配到的训练样本为0，则我们将尝试计算 0个样本点的平均值，这是无法计算的。
        - 如果发生这种情况，最常见的做法就是消除该集群（更常见的做法）；
        - 但如果不想要消除集群，那么就需要重新随机初始化该集群的质心，并希望它在下一轮能够分配到一些训练样本；



## 3. `k-means`算法的优化目标

 有如下定义：
$$
c^{(i)}=index \space of \space cluster(1,2...,k) \space to which \space example \space x^{(i)} \space is \space currently \space assinged \\
即 \\
c^{(i)} 表示样本x^{(i)}被分配到的簇（集群）所在的编号（索引）
$$

$$
\mu_k = cluster \space centroid \space k \\
即 \\
\mu_k 代表第k个簇（集群）的质心（中心）
$$

$$
\mu_{c^{(i)}} = cluster \space centroid \space of \space cluster \space to \space which \space example \space x^{(i)} \space has \space been \space assigned \\
即 \\
\mu_{c^{(i)}} 表示样本x^{(i)}被分配到的簇（集群）的质心
$$



则 `K-means`的 代价函数（损失函数）为：
$$
J(c^{(1)},...,c^{(m)},\mu_1, ...,\mu_k) = \frac {1}{m} \sum_{i=1}^{m} ||x^{(i)} - \mu_{c^{(i)}}||^2
$$
我们的目标为：
$$
min_{c^{(1)},...,c^{(m)},\mu_1, ...,\mu_k} J(c^{(1)},...,c^{(m)},\mu_1, ...,\mu_k)
$$




## 4.初始化 `k-means`

### 4.1 随机初始化

`K-means` 聚类算法的第一步是选择随机位置作为聚类质心 $\mu_1, \mu_2, ..., \mu_k$ 作为初始猜测。

![image-20240113135907658](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113135907658.png)



**随机初始化**：

1. 选择 $k<m$
2. 最常见的方法是随机选择 $k$ 个训练样本，然后我们将随机选择的 $k$ 个样本作为初始化的 $k$ 个簇的质心 $\mu_1, \mu_2, ..., \mu_k$ 



假设我们有以下训练集，且要使用 `K-means` 算法将训练集划分为 $k=3$ 个簇：

<img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113140857159.png" alt="image-20240113140857159" style="zoom:50%;" />

那么运行经过随机初始化之后的 `K-means` 算法，可能得到如下结果：

<img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113141041482.png" alt="image-20240113141041482" style="zoom:50%;" />

这是一个比较好的聚类结果，很好地将数据划分为了3个簇。但是如果使用不同的初始化，可能得到如下结果：

<img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113141148162.png" alt="image-20240113141148162" style="zoom:50%;" />

这看起来不太好。事实证明，这是一个局部最优解：当`K-means`算法试图最小化 **失真成本函数**
$$
J(c^{(1)},...,c^{(m)},\mu_1, ...,\mu_k) = \frac {1}{m} \sum_{i=1}^{m} ||x^{(i)} - \mu_{c^{(i)}}||^2
$$
时，由于做了一个较差的随机初始化，则使得最小化 ”失真成本函数“ 时恰好陷入了局部最小值。

以下是另一个局部最小值的示例（也使用了不同的随机初始化）：

<img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113141556914.png" alt="image-20240113141556914" style="zoom:50%;" />

### 4.2 多次运行 `k-means`

通过上述的分析，在使用不同的随机初始化时，运行`K-means`可能得到不同的结果（不同的局部最优值）。因此，如果我们想要**使用 `k-menas` 进行多次尝试以找到最佳的局部最优值，**则**可以尝试多个随机初始化，然后有机会找到最佳的局部最优值**。

另一种尝试找到最佳的局部最优值的方法是多次运行`k-means`算法，以尝试找到最佳的局部最优值。

**当我们运行多次`k-means`算法，并得到多个不同的聚类方案之后，要选择最佳的局部最优值的方法是计算这些方案的成本函数的值，然后选择其中成本函数的值最低的聚类方案**。

下面将其更正式地写成一个算法，并使用不同的随机初始化来多次运行`k-means`算法并最终进行排名：
$$
\text {for i = 1 to 100 } \{ 
\\
	\text{Randomly initialize k-means} \\
	\text{Run K-means.} Get \space c^{(1)},..., c^{(m)}, u_1,..., u_k \\
	\text{Computer cost function (distortion)} \\
	J(c^{(1)},...,c^{(m)},\mu_1, ...,\mu_k) = \frac {1}{m} \sum_{i=1}^{m} ||x^{(i)} - \mu_{c^{(i)}}||^2
	\\
\}\\

\text{Pick set of clusters that gabe lowest cost}
$$
事实证明，通过上述的方法，通常会得到一组更好的集群，与只运行一次 `K-means`算法相比，失真函数的值要低的多。

在使用这种方法时，运行 `[50, 1000]` 次是很常见的，但是，如果运行`K-means`算法超过1000次，则计算耗费往往会很昂贵，且得到的收益较小。



## 5. 选择簇（集群）的数量 $k$

`K-means` 算法需要参数 `k`作为输入，`k`即我们希望算法找到的聚类数量，下面将讲解如何决定聚类的数量，即如何选择 $k$ 的值。

### 5.1 Elbow Method（肘部法则）

这是一种常用的启发式方法。它通过绘制不同的`k`值对应的簇内平方误差（失真函数的值），并观察失真函数随着`k`值的变化趋势。当增加`k`值时，失真函数的值往往会逐渐减小。但是，随着`k`值继续增大，失真函数的改善效果会逐渐减弱。在图形中，这种变化可能会呈现出一个明显的 “肘部”，这个 ”肘部“ 对应的 `k`值可以被认为是一个合适的选择：

<img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113144553954.png" alt="image-20240113144553954" style="zoom:67%;" />

但是在很多时候，失真成本函数的值随着`k`值的变化趋势并不会呈现出一种”肘部“，而只是平滑地减少，没有明确的”肘部“来供我们选择`k`值，如下图所示：

<img src="C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113144755278.png" alt="image-20240113144755278" style="zoom: 67%;" />



> 顺便说一下，一种**不起作用**的技术是选择`k` 以最小化成本函数$J$，因为这样做会导致我们几乎总是只选择 $k$ 的最大可能只，因为拥有更多的集群几乎总是会降低成本函数 $J$.



### 5.2 根据聚类结果应用的性能来评估`k-means`

![image-20240113145458114](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113145458114.png)

通常，我们运行`k-means` 算法是为了让集群用于稍后或某些下游目的，则我们**可以通过根据 `k-menas` 为后来的（下游的）目的的执行的性能来评估它**。



例如，在使用`K-means`算法为衣服尺码数据集进行聚类时，可能有以下两种聚类结果：

![image-20240113145601884](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20240113145601884.png)

此时，我们可以根据聚类结果（此处为划分的尺码种类数目）为下游目的的执行的性能来进行评估，例如假设用户觉得划分为5个尺码可能使得衣服更加合身，且划分为5个尺码之后制作衣服的成本并不会增加很多，则衣服制造厂商可能就会更愿意选择划分为5个尺码（即$k=5$的聚类结果）。

